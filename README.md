## Setting up LLaVa
For generating Image captions we need to set up LLaVa by following the instructions in [LLaVa](https://github.com/haotian-liu/LLaVA/tree/main).
After setting up LLaVa, we can give an image and a text prompt as input to image_captioner.py which generates the captions for the given image.

## test.ipynb
This notebook contains code for installing owlVIT and SAM and using those to segment regions in the image based on the vocabulary generated by the image captioner.
